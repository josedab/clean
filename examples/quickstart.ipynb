{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean: Quick Start Guide\n",
    "\n",
    "This notebook demonstrates the basic usage of Clean for data quality analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install clean if needed\n",
    "# !pip install clean-data-quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from clean import DatasetCleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample Data\n",
    "\n",
    "Let's create a sample dataset with some intentional quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_samples = 500\n",
    "\n",
    "# Create features\n",
    "df = pd.DataFrame({\n",
    "    'feature_1': np.random.randn(n_samples),\n",
    "    'feature_2': np.random.randn(n_samples),\n",
    "    'feature_3': np.random.randn(n_samples),\n",
    "    'category': np.random.choice(['A', 'B', 'C'], n_samples),\n",
    "})\n",
    "\n",
    "# Create labels with some errors (5% wrong)\n",
    "true_labels = (df['feature_1'] + df['feature_2'] > 0).astype(int)\n",
    "labels = true_labels.copy()\n",
    "error_idx = np.random.choice(n_samples, size=25, replace=False)\n",
    "labels.iloc[error_idx] = 1 - labels.iloc[error_idx]\n",
    "df['label'] = labels\n",
    "\n",
    "# Add some duplicates\n",
    "df.iloc[100] = df.iloc[0]\n",
    "df.iloc[200] = df.iloc[0]\n",
    "\n",
    "# Add outliers\n",
    "df.iloc[50, 0] = 10\n",
    "df.iloc[51, 1] = -10\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize DatasetCleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = DatasetCleaner(\n",
    "    data=df,\n",
    "    label_column='label',\n",
    "    task='classification'\n",
    ")\n",
    "print(cleaner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = cleaner.analyze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Specific Issues\n",
    "\n",
    "### Label Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_errors = report.label_errors()\n",
    "print(f\"Found {len(label_errors)} label errors\")\n",
    "label_errors.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = report.duplicates()\n",
    "print(f\"Found {len(duplicates)} duplicate pairs\")\n",
    "duplicates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = report.outliers()\n",
    "print(f\"Found {len(outliers)} outliers\")\n",
    "outliers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = cleaner.get_clean_data(\n",
    "    remove_duplicates=True,\n",
    "    remove_outliers='conservative'\n",
    ")\n",
    "\n",
    "print(f\"Original: {len(df)} samples\")\n",
    "print(f\"Clean: {len(clean_df)} samples\")\n",
    "print(f\"Removed: {len(df) - len(clean_df)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Review Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_queue = cleaner.get_review_queue(max_items=20)\n",
    "review_queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to JSON\n",
    "# report.save_json('report.json')\n",
    "\n",
    "# Export to HTML\n",
    "# report.save_html('report.html')\n",
    "\n",
    "# Or get as dict\n",
    "report_dict = report.to_dict()\n",
    "print(f\"Report keys: {list(report_dict.keys())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
